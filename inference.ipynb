{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3e12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#only need to install once\n",
    "#!{sys.executable} -m pip install librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import butter,filtfilt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision.io import read_image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfb72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low-pass filtering function\n",
    "def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d36b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, model):\n",
    "    image_tensor = image.float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = F.sigmoid(output).data.cpu().numpy()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51244180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  NVIDIA Tegra X1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU name: \", torch.cuda.get_device_name(0))\n",
    "resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "resnet18.fc = torch.nn.Linear(512, 1) #just 1 output, will use sigmoid later\n",
    "PATH = './e6992/patient3-8.pth' #load the saved weights\n",
    "resnet18.load_state_dict(torch.load(PATH))\n",
    "resnet18.eval() #set eval mode\n",
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868554a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs, samples = wavfile.read('./e6992/00001010-100507.wav')\n",
    "total_seconds = int(len(samples)/Fs)\n",
    "\n",
    "for second in range(1666, 1667, 1): #go through every second rolling window\n",
    "    \n",
    "    x = samples[(second)*Fs:(second+60)*Fs] #take out the selected minute\n",
    "\n",
    "    cutoff = 1000 #define filter cutoff frequency (1000Hz)\n",
    "    order = 5 #define filter order\n",
    "    x_filtered = butter_lowpass_filter(x, cutoff, Fs, order) #low-pass filtering\n",
    "\n",
    "    x_downsampled = signal.resample(x_filtered, 2048*60) #downsample the function to 2kHz\n",
    "    new_Fs = 2048\n",
    "    \n",
    "    n_fft = 512 #length of fft, 512 optimal for speech\n",
    "\n",
    "    sgram = librosa.stft(x_downsampled, center=False, n_fft=n_fft)\n",
    "    sgram_mag, _ = librosa.magphase(sgram)\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr=new_Fs, n_fft=n_fft)\n",
    "    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
    "    #for raw graphs to save\n",
    "    #librosa.display.specshow(mel_sgram, sr=Fs, n_fft=n_fft, fmin=22, fmax=700)\n",
    "    #for graphs with axis and scale\n",
    "    librosa.display.specshow(mel_sgram, sr=new_Fs*4, n_fft=n_fft, fmin=22, fmax=700)\n",
    "    #plt.colorbar(format='%+2.0f dB')\n",
    "    file = '00000995-100507' + '_0' + str(second) + '.jpg'\n",
    "    #print(file)\n",
    "    plt.savefig(file) #need to save the figure as a jpg\n",
    "    plt.close()\n",
    "    img = cv2.imread(file) #re-open the file to crop off white space\n",
    "    img = img[34:253, 53:390]\n",
    "    cv2.imwrite(file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b086c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 219, 337])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /media/nvidia/NVME/pytorch/pytorch-v1.9.0/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976793\n",
      "0=healthy 1=apnea - result:  1\n"
     ]
    }
   ],
   "source": [
    "img_path = '00000995-100507_01666.jpg'\n",
    "image = read_image(img_path)\n",
    "print(image.shape)\n",
    "\n",
    "#display selected image, commented out for timing\n",
    "#img = image.permute(1,2,0)\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "\n",
    "result = predict_image(image, resnet18)[0][0]\n",
    "print(result)\n",
    "print(\"0=healthy 1=apnea - result: \", round(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dce538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
